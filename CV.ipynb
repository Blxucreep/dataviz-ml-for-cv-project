{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LE QUERNEC Loévan, EL HACHEM Gabriel, and FALCK Jade, DIA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI & DataViz / Machine learning for CV project: Human Action Recognition (HAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "train_csv = 'training_set.csv' # file with labeled data\n",
    "test_csv = 'testing_set.csv' # file with unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurrences of each label\n",
    "print(\"Number of lines in the training set:\", len(train_df), \"\\n\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualize the distribution of the labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='label', data=train_df, order=train_df['label'].value_counts().index)\n",
    "plt.title('Distribution of the classes in the training set')\n",
    "plt.xlabel('Number of occurrences')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that the data is perfectly balanced, which is a good thing for the training of our model. Do a visualization of the data to see the distribution of the classes is then not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of caracteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will encode the labels of the actions to integers. This will allow us to use them in the model. We will be able to retrieve the original labels with the variable `label_mapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels\n",
    "label_mapping = {label: idx for idx, label in enumerate(train_df['label'].unique())}\n",
    "train_df['label_idx'] = train_df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "img_width, img_height = 128, 128 # dimensions of our images\n",
    "\n",
    "# prepare the training data\n",
    "def load_images_from_dataframe(df, directory, img_width, img_height):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(directory, row['filename'])\n",
    "        print(img_path)\n",
    "        if os.path.exists(img_path):\n",
    "            # load and rescale the image\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img_array = img_to_array(img) / 255.0 # normalize\n",
    "            images.append(img_array)\n",
    "            if 'label_idx' in row:\n",
    "                labels.append(row['label_idx'])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# load the traing images\n",
    "X_train, y_train = load_images_from_dataframe(train_df, train_dir, img_width, img_height)\n",
    "y_train = to_categorical(y_train, num_classes=len(label_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test images\n",
    "X_test, _ = load_images_from_dataframe(test_df, test_dir, img_width, img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the model(s) you want to launch the training and create a model file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = 0\n",
    "mobilenet = 0\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnn:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "    # build a simple CNN\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_mapping), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compile the model\n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    cnn_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "    # save the model\n",
    "    cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mobilenet:\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "    # load the base model MobileNetV2 pre-trained\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(len(label_mapping), activation='softmax')(x)\n",
    "\n",
    "    # create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "    # save the model\n",
    "    model.save('mobilenet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the model you want to use to make the predictions and have the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load the model\n",
    "cnn_model = tf.keras.models.load_model(f'cnn_model.h5')\n",
    "mobilenet_model = tf.keras.models.load_model(f'mobilenet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the predictions\n",
    "print(\"Train predictions on the CNN model:\")\n",
    "cnn_train_predictions = cnn_model.predict(X_train)\n",
    "cnn_train_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in cnn_train_predictions]\n",
    "\n",
    "print(\"Test predictions on the CNN model:\")\n",
    "cnn_test_predictions = cnn_model.predict(X_test)\n",
    "cnn_test_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in cnn_test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the predictions\n",
    "print(\"Train predictions on the MobileNet model:\")\n",
    "mobilenet_train_predictions = mobilenet_model.predict(X_train)\n",
    "mobilenet_train_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in mobilenet_train_predictions]\n",
    "\n",
    "print(\"Test predictions on the MobileNet model:\")\n",
    "mobilenet_test_predictions = mobilenet_model.predict(X_test)\n",
    "mobilenet_test_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in mobilenet_test_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy on the training set\n",
    "true_train_labels = [list(label_mapping.keys())[label] for label in np.argmax(y_train, axis=1)]\n",
    "\n",
    "cnn_correct_predictions = sum(pred == true for pred, true in zip(cnn_train_predicted_labels, true_train_labels))\n",
    "cnn_train_accuracy = cnn_correct_predictions / len(true_train_labels) * 100\n",
    "\n",
    "print(f\"CNN accuracy on the training set: {cnn_train_accuracy:.2f}%\")\n",
    "\n",
    "mobilenet_correct_predictions = sum(pred == true for pred, true in zip(mobilenet_train_predicted_labels, true_train_labels))\n",
    "mobilenet_train_accuracy = mobilenet_correct_predictions / len(true_train_labels) * 100\n",
    "\n",
    "print(f\"MobileNet accuracy on the training set: {mobilenet_train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "accuracies = {\n",
    "    'CNN': cnn_train_accuracy,\n",
    "    'MobileNet': mobilenet_train_accuracy\n",
    "}\n",
    "\n",
    "# plot the accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy of Different Models')\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# function to plot heatmap of confusion matrix\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, model_name):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=list(label_mapping.keys()))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(label_mapping.keys()), yticklabels=list(label_mapping.keys()))\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# plot for CNN model\n",
    "plot_confusion_matrix(true_train_labels, cnn_train_predicted_labels, 'CNN model')\n",
    "\n",
    "# plot for MobileNet model\n",
    "plot_confusion_matrix(true_train_labels, mobilenet_train_predicted_labels, 'MobileNet model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display images with predictions and true labels\n",
    "def display_images_with_predictions_and_true_labels(images, predictions, true_labels, num_images=10):\n",
    "    # limit the number of images\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1) # 2 rows, 5 columns\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # compare the prediction with the true label\n",
    "        predicted_label = predictions[i]\n",
    "        true_label = true_labels[i]\n",
    "        color = \"green\" if predicted_label == true_label else \"red\"\n",
    "        \n",
    "        # add the title and the color\n",
    "        plt.title(f\"Predicted: {predicted_label}\\nTrue: {true_label}\", color=color, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_display = (X_train * 255).astype(np.uint8) # convert back to 0-255 range\n",
    "\n",
    "# print the first 10 images with predictions and true labels\n",
    "display_images_with_predictions_and_true_labels(\n",
    "    images=X_train_display[:10],\n",
    "    predictions=cnn_train_predicted_labels[:10],\n",
    "    true_labels=true_train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display images with predictions\n",
    "def display_images_with_predictions(images, predictions, num_images=10):\n",
    "    # limit the number of images\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1) # 2 rows, 5 columns\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.title(f\"Predicted: {predictions[i]}\", fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_display = (X_test * 255).astype(np.uint8) # convert back to 0-255 range\n",
    "\n",
    "# print the first 10 images with predictions\n",
    "display_images_with_predictions(\n",
    "    images=X_test_display[:10],\n",
    "    predictions=cnn_test_predicted_labels[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_activation_maps(model, img_array, layer_name):\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(img_array)\n",
    "    \n",
    "    # Vérifier les dimensions pour éviter des erreurs\n",
    "    if len(intermediate_output.shape) == 4:  # Batch, Height, Width, Channels\n",
    "        return intermediate_output\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected dimensions for activation maps.\")\n",
    "\n",
    "def display_activation_maps(activation_maps, images, num_images=5):\n",
    "    num_images = min(num_images, len(images))\n",
    "    for i in range(num_images):\n",
    "        fig, axes = plt.subplots(1, len(activation_maps[i]), figsize=(20, 5))\n",
    "        \n",
    "        for j in range(len(activation_maps[i])):\n",
    "            # Affichez chaque canal comme une image séparée\n",
    "            axes[j].imshow(activation_maps[i][:, :, j], cmap='viridis')\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.suptitle(f\"Activation Maps for Image {i+1}\")\n",
    "        plt.show()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "layer_name = 'conv2d_1'  # Vérifiez le nom exact de la couche dans votre modèle\n",
    "activation_maps = get_activation_maps(cnn_model, X_test[:5], layer_name)\n",
    "\n",
    "# Display les 5 premières images et leurs activation maps\n",
    "display_activation_maps(activation_maps, X_test_display[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# apply TSNE on the CNN model predictions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "cnn_tsne_results = tsne.fit_transform(cnn_train_predictions)\n",
    "\n",
    "# apply TSNE on the MobileNet model predictions\n",
    "mobilenet_tsne_results = tsne.fit_transform(mobilenet_train_predictions)\n",
    "\n",
    "# plot for CNN model\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=cnn_tsne_results[:, 0], y=cnn_tsne_results[:, 1], hue=true_train_labels, palette='tab10', legend='full')\n",
    "plt.title('TSNE visualization of CNN model predictions')\n",
    "plt.xlabel('TSNE component 1')\n",
    "plt.ylabel('TSNE component 2')\n",
    "plt.show()\n",
    "\n",
    "# plot for MobileNet model\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=mobilenet_tsne_results[:, 0], y=mobilenet_tsne_results[:, 1], hue=true_train_labels, palette='tab10', legend='full')\n",
    "plt.title('TSNE visualization of MobileNet model predictions')\n",
    "plt.xlabel('TSNE component 1')\n",
    "plt.ylabel('TSNE component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of the ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented images from the training set\n",
    "augmented_images, augmented_labels = next(datagen.flow(X_train, y_train, batch_size=10))\n",
    "\n",
    "# Function to display augmented images\n",
    "def display_augmented_images(images, labels, num_images=10):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Label: {list(label_mapping.keys())[np.argmax(labels[i])]}\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display augmented images\n",
    "display_augmented_images(augmented_images, augmented_labels)\n",
    "\n",
    "# Function to get activation maps for augmented images\n",
    "def get_activation_maps_for_augmented_images(model, images, layer_name):\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(images)\n",
    "    return intermediate_output\n",
    "\n",
    "# Example usage for CNN model\n",
    "cnn_layer_name = 'conv2d_1'  # Change this to the name of the layer you want to visualize\n",
    "cnn_activation_maps = get_activation_maps_for_augmented_images(cnn_model, augmented_images, cnn_layer_name)\n",
    "display_activation_maps(cnn_activation_maps, augmented_images)\n",
    "\n",
    "# Example usage for MobileNet model\n",
    "mobilenet_layer_name = 'block_1_expand_relu'  # Change this to the name of the layer you want to visualize\n",
    "mobilenet_activation_maps = get_activation_maps_for_augmented_images(mobilenet_model, augmented_images, mobilenet_layer_name)\n",
    "display_activation_maps(mobilenet_activation_maps, augmented_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
