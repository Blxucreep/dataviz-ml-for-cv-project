{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LE QUERNEC Lo√©van, EL HACHEM Gabriel, and FALCK Jade, DIA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI & DataViz / Machine learning for CV project: Human Action Recognition (HAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paths\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "train_csv = 'training_set.csv' # file with labeled data\n",
    "test_csv = 'testing_set.csv' # file with unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurrences of each label\n",
    "print(\"Number of lines in the training set:\", len(train_df), \"\\n\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# visualize the distribution of the labels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(y='label', data=train_df, order=train_df['label'].value_counts().index)\n",
    "plt.title('Distribution of the classes in the training set')\n",
    "plt.xlabel('Number of occurrences')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see is that the data is perfectly balanced, which is a good thing for the training of our model. Do a visualization of the data to see the distribution of the classes is then not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computational results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of caracteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will encode the labels of the actions to integers. This will allow us to use them in the model. We will be able to retrieve the original labels with the variable `label_mapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels\n",
    "label_mapping = {label: idx for idx, label in enumerate(train_df['label'].unique())}\n",
    "train_df['label_idx'] = train_df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "img_width, img_height = 128, 128 # dimensions of our images\n",
    "\n",
    "# prepare the training data\n",
    "def load_images_from_dataframe(df, directory, img_width, img_height):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(directory, row['filename'])\n",
    "        print(img_path)\n",
    "        if os.path.exists(img_path):\n",
    "            # load and rescale the image\n",
    "            img = load_img(img_path, target_size=(img_width, img_height))\n",
    "            img_array = img_to_array(img) / 255.0 # normalize\n",
    "            images.append(img_array)\n",
    "            if 'label_idx' in row:\n",
    "                labels.append(row['label_idx'])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# load the traing images\n",
    "X_train, y_train = load_images_from_dataframe(train_df, train_dir, img_width, img_height)\n",
    "y_train = to_categorical(y_train, num_classes=len(label_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test images\n",
    "X_test, _ = load_images_from_dataframe(test_df, test_dir, img_width, img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the model(s) you want to launch the training and create a model file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = 0\n",
    "mobilenet = 0\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnn:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "    # build a simple CNN\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_mapping), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # compile the model\n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    cnn_model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "    # save the model\n",
    "    cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mobilenet:\n",
    "    from tensorflow.keras.applications import MobileNetV2\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "\n",
    "    # load the base model MobileNetV2 pre-trained\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    predictions = Dense(len(label_mapping), activation='softmax')(x)\n",
    "\n",
    "    # create the model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "\n",
    "    # save the model\n",
    "    model.save('mobilenet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the model you want to use to make the predictions and have the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load the model\n",
    "cnn_model = tf.keras.models.load_model(f'cnn_model.h5')\n",
    "mobilenet_model = tf.keras.models.load_model(f'mobilenet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the predictions\n",
    "print(\"Train predictions on the CNN model:\")\n",
    "cnn_train_predictions = cnn_model.predict(X_train)\n",
    "cnn_train_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in cnn_train_predictions]\n",
    "\n",
    "print(\"Test predictions on the CNN model:\")\n",
    "cnn_test_predictions = cnn_model.predict(X_test)\n",
    "cnn_test_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in cnn_test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the predictions\n",
    "print(\"Train predictions on the MobileNet model:\")\n",
    "mobilenet_train_predictions = mobilenet_model.predict(X_train)\n",
    "mobilenet_train_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in mobilenet_train_predictions]\n",
    "\n",
    "print(\"Test predictions on the MobileNet model:\")\n",
    "mobilenet_test_predictions = mobilenet_model.predict(X_test)\n",
    "mobilenet_test_predicted_labels = [list(label_mapping.keys())[np.argmax(pred)] for pred in mobilenet_test_predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the accuracy on the training set\n",
    "true_train_labels = [list(label_mapping.keys())[label] for label in np.argmax(y_train, axis=1)]\n",
    "\n",
    "cnn_correct_predictions = sum(pred == true for pred, true in zip(cnn_train_predicted_labels, true_train_labels))\n",
    "cnn_train_accuracy = cnn_correct_predictions / len(true_train_labels) * 100\n",
    "\n",
    "print(f\"CNN accuracy on the training set: {cnn_train_accuracy:.2f}%\")\n",
    "\n",
    "mobilenet_correct_predictions = sum(pred == true for pred, true in zip(mobilenet_train_predicted_labels, true_train_labels))\n",
    "mobilenet_train_accuracy = mobilenet_correct_predictions / len(true_train_labels) * 100\n",
    "\n",
    "print(f\"MobileNet accuracy on the training set: {mobilenet_train_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies\n",
    "accuracies = {\n",
    "    'CNN': cnn_train_accuracy,\n",
    "    'MobileNet': mobilenet_train_accuracy\n",
    "}\n",
    "\n",
    "# plot the accuracies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracies.keys(), accuracies.values(), color=['blue', 'green'])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training Accuracy of Different Models')\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# function to plot heatmap of confusion matrix\n",
    "def plot_confusion_matrix(true_labels, predicted_labels, model_name):\n",
    "    cm = confusion_matrix(true_labels, predicted_labels, labels=list(label_mapping.keys()))\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=list(label_mapping.keys()), yticklabels=list(label_mapping.keys()))\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title(f'Confusion matrix for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# plot for CNN model\n",
    "plot_confusion_matrix(true_train_labels, cnn_train_predicted_labels, 'CNN model')\n",
    "\n",
    "# plot for MobileNet model\n",
    "plot_confusion_matrix(true_train_labels, mobilenet_train_predicted_labels, 'MobileNet model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display images with predictions and true labels\n",
    "def display_images_with_predictions_and_true_labels(images, predictions, true_labels, num_images=10):\n",
    "    # limit the number of images\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1) # 2 rows, 5 columns\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # compare the prediction with the true label\n",
    "        predicted_label = predictions[i]\n",
    "        true_label = true_labels[i]\n",
    "        color = \"green\" if predicted_label == true_label else \"red\"\n",
    "        \n",
    "        # add the title and the color\n",
    "        plt.title(f\"Predicted: {predicted_label}\\nTrue: {true_label}\", color=color, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_display = (X_train * 255).astype(np.uint8) # convert back to 0-255 range\n",
    "\n",
    "# print the first 10 images with predictions and true labels\n",
    "display_images_with_predictions_and_true_labels(\n",
    "    images=X_train_display[:10],\n",
    "    predictions=cnn_train_predicted_labels[:10],\n",
    "    true_labels=true_train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display images with predictions\n",
    "def display_images_with_predictions(images, predictions, num_images=10):\n",
    "    # limit the number of images\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1) # 2 rows, 5 columns\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.title(f\"Predicted: {predictions[i]}\", fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_display = (X_test * 255).astype(np.uint8) # convert back to 0-255 range\n",
    "\n",
    "# print the first 10 images with predictions\n",
    "display_images_with_predictions(\n",
    "    images=X_test_display[:10],\n",
    "    predictions=cnn_test_predicted_labels[:10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_channels_by_variance(activation_maps, top_k=8):\n",
    "    # check the dimensions of the activation maps\n",
    "    if len(activation_maps.shape) == 3: # single image (height, width, channels)\n",
    "        channel_variances = np.var(activation_maps, axis=(0, 1))\n",
    "    elif len(activation_maps.shape) == 4: # batch of images (batch, height, width, channels)\n",
    "        channel_variances = np.var(activation_maps, axis=(0, 1, 2))\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected dimensions for activation_maps: {}\".format(activation_maps.shape))\n",
    "    \n",
    "    # find the indices of the top-k channels with highest variance\n",
    "    top_channels = np.argsort(channel_variances)[-top_k:]\n",
    "\n",
    "    return top_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_channels_by_mean(activation_maps, top_k=8):\n",
    "    # check the dimensions of the activation maps\n",
    "    if len(activation_maps.shape) == 2: # (positions, channels)\n",
    "        channel_means = np.mean(activation_maps, axis=0)\n",
    "    elif len(activation_maps.shape) == 3: # (height, width, channels)\n",
    "        channel_means = np.mean(activation_maps, axis=(0, 1))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected dimensions for activation_maps: {activation_maps.shape}\")\n",
    "    \n",
    "    # find the indices of the top-k channels with highest mean\n",
    "    top_channels = np.argsort(channel_means)[-top_k:]\n",
    "\n",
    "    return top_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_channels_by_max(activation_maps, top_k=8):\n",
    "    # check the dimensions of the activation maps\n",
    "    if len(activation_maps.shape) == 2: # (positions, channels)\n",
    "        channel_max = np.max(activation_maps, axis=0)\n",
    "    elif len(activation_maps.shape) == 3: # (height, width, channels)\n",
    "        channel_max = np.max(activation_maps, axis=(0, 1))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected dimensions for activation_maps: {activation_maps.shape}\")\n",
    "    \n",
    "    # find the indices of the top-k channels with highest max\n",
    "    top_channels = np.argsort(channel_max)[-top_k:]\n",
    "\n",
    "    return top_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_important_activation_maps(activation_maps, image, important_channels, max_channels=8):\n",
    "    # limit the number of channels\n",
    "    important_channels = important_channels[:max_channels]\n",
    "    \n",
    "    # number of important channels\n",
    "    num_channels = len(important_channels)\n",
    "    fig, axes = plt.subplots(1, num_channels + 1, figsize=(20, 5))\n",
    "    \n",
    "    # display the original image\n",
    "    axes[0].imshow(image.astype(\"uint8\"))\n",
    "    axes[0].set_title(\"Image originale\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # display the important channels\n",
    "    for i, channel in enumerate(important_channels):\n",
    "        activation_map = activation_maps[:, :, channel]\n",
    "        axes[i + 1].imshow(activation_map, cmap='viridis')\n",
    "        axes[i + 1].set_title(f\"Canal {channel}\")\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def get_activation_maps(model, img_array, layer_name):\n",
    "    # create a model that will return these outputs, given the model input\n",
    "    intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "    intermediate_output = intermediate_layer_model.predict(img_array)\n",
    "    \n",
    "    # check the dimensions of the intermediate output\n",
    "    if len(intermediate_output.shape) == 4: # (batch, height, width, channels)\n",
    "        return intermediate_output\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected dimensions for activation maps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the activation maps for the first image\n",
    "activation_maps = get_activation_maps(cnn_model, X_test, 'conv2d_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top channels by variance\n",
    "top_channels_variance = get_top_channels_by_variance(activation_maps[0], top_k=8)\n",
    "\n",
    "# display the important activation maps\n",
    "display_important_activation_maps(\n",
    "    activation_maps=activation_maps[0],\n",
    "    image=X_test_display[0],\n",
    "    important_channels=top_channels_variance,\n",
    "    max_channels=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top channels by mean\n",
    "top_channels_mean = get_top_channels_by_mean(activation_maps[0], top_k=8)\n",
    "\n",
    "# display the important activation maps\n",
    "display_important_activation_maps(\n",
    "    activation_maps=activation_maps[0],\n",
    "    image=X_test_display[0],\n",
    "    important_channels=top_channels_mean,\n",
    "    max_channels=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top channels by max\n",
    "top_channels_max = get_top_channels_by_max(activation_maps[0], top_k=8)\n",
    "\n",
    "# display the important activation maps\n",
    "display_important_activation_maps(\n",
    "    activation_maps=activation_maps[0],\n",
    "    image=X_test_display[0],\n",
    "    important_channels=top_channels_max,\n",
    "    max_channels=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# apply TSNE on the CNN model predictions\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "cnn_tsne_results = tsne.fit_transform(cnn_train_predictions)\n",
    "\n",
    "# apply TSNE on the MobileNet model predictions\n",
    "mobilenet_tsne_results = tsne.fit_transform(mobilenet_train_predictions)\n",
    "\n",
    "# plot for CNN model\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=cnn_tsne_results[:, 0], y=cnn_tsne_results[:, 1], hue=true_train_labels, palette='tab10', legend='full')\n",
    "plt.title('TSNE visualization of CNN model predictions')\n",
    "plt.xlabel('TSNE component 1')\n",
    "plt.ylabel('TSNE component 2')\n",
    "plt.show()\n",
    "\n",
    "# plot for MobileNet model\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(x=mobilenet_tsne_results[:, 0], y=mobilenet_tsne_results[:, 1], hue=true_train_labels, palette='tab10', legend='full')\n",
    "plt.title('TSNE visualization of MobileNet model predictions')\n",
    "plt.xlabel('TSNE component 1')\n",
    "plt.ylabel('TSNE component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and interpretation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
